# Extract Patient Voice from Social Media Posts
## Binary Text Classification of Unlabeled Data on Twitter Corpus

<p>The advent of deep learning in recent years has introduced many state-of-the-art algorithms in Natural Language Processing. But they all come at a cost, models requiring huge amounts of training data. This creates a bottleneck in leveraging these solutions for most real-world applications where we do not have such readily available data. This paper explores ways to handle this problem while attempting to solve a particular use case within the health care industry - filtering patient experiences from social media websites. We demonstrate two data labeling techniques, namely Weak Supervision and Active Learning to create a huge, labeled corpus. Experiments to quantify the quality of this generated training dataset to build a binary classification model on BERT and BioBERT architectures achieve an accuracy of 87% and 89%. Our study shows that by providing minimal annotated data, these labeling techniques can generalize well to create a huge, labeled dataset to help leverage the best models from the literature.</p>


